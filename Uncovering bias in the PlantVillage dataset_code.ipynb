{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electric-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operating-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'PlantVillage-Dataset-master/raw/color/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "superior-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = []\n",
    "class_names = []\n",
    "for class_folder in glob.glob(main_path + '*'):\n",
    "    class_folders.append(class_folder)\n",
    "    class_names.append(class_folder.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "helpful-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "y = []\n",
    "y_names = []\n",
    "for i in range(len(class_names)):\n",
    "    for im_path in glob.glob(class_folders[i] + '/*'):\n",
    "        im = cv2.imread(im_path)\n",
    "        if im is None:continue\n",
    "        if im.shape != (256, 256, 3):continue\n",
    "        images.append(im)\n",
    "        y.append(i)\n",
    "        y_names.append(class_folders[i].split('/')[-1])\n",
    "        \n",
    "images = np.array(images)\n",
    "y_names = np.array(y_names)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "american-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54305, 256, 256, 3), (54305,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "patient-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(images):\n",
    "    mid_point = int(images.shape[1]/2)\n",
    "    tl = images[:, 0, 0, :]\n",
    "    tr = images[:, 0, -1, :]\n",
    "    bl = images[:, -1, 0, :]\n",
    "    br = images[:, -1, -1, :]\n",
    "    lm = images[:, mid_point, 0, :]\n",
    "    tm = images[:, 0, mid_point, :]\n",
    "    bm = images[:, -1, mid_point, :]\n",
    "    rm = images[:, mid_point, -1, :]\n",
    "    X = np.stack((tl, tr, bl, br, lm, tm, bm, rm), axis=1)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "congressional-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_extractor(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "egyptian-cowboy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54305, 24), (54305,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "severe-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "agreed-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aware-blend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_result = clf.score(X_test, y_test)\n",
    "np.round(acc_result*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "animated-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random guess\n",
    "np.round(100/38, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-farming",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "immune-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demographic-polymer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mnist.shape, X_test_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accurate-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mnist_8px = feature_extractor(X_train_mnist.reshape(60000, 28, 28, 1))\n",
    "X_test_mnist_8px = feature_extractor(X_test_mnist.reshape(10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "weekly-timer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 8), (10000, 8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mnist_8px.shape, X_test_mnist_8px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "global-standard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mnist = RandomForestClassifier(random_state=0)\n",
    "clf_mnist.fit(X_train_mnist_8px, y_train_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "concerned-richards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_result = clf_mnist.score(X_test_mnist_8px, y_test_mnist)\n",
    "np.round(acc_result*100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-archive",
   "metadata": {},
   "source": [
    "## Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sustainable-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "X_im_sharpness = []\n",
    "X_bg_sharpness = []\n",
    "X_seg_sharpness = []\n",
    "for i in range(len(class_names)):\n",
    "    for im_path in glob.glob(class_folders[i] + '/*.JPG'):\n",
    "        \n",
    "        # path of the corresponding foreground image\n",
    "        splitted = im_path.split('/')\n",
    "        color_name = splitted[-1]\n",
    "        segmented_name = color_name[:-4] + '_final_masked.jpg'\n",
    "        splitted[2] = 'segmented'\n",
    "        splitted[-1] = segmented_name\n",
    "        seg_path = '/'.join(splitted)\n",
    "        \n",
    "        im = cv2.imread(im_path)\n",
    "        seg = cv2.imread(seg_path)\n",
    "        \n",
    "        if im is None:continue\n",
    "        if seg is None:continue\n",
    "        \n",
    "        if im.shape == (256,256,3):\n",
    "            if seg.shape == (256,256,3):\n",
    "                c1 = seg[:, :, 0]==0\n",
    "                c2 = seg[:, :, 1]==0\n",
    "                c3 = seg[:, :, 2]==0\n",
    "                mask = c1*c2*c3\n",
    "                bg = np.zeros_like(im)\n",
    "                bg[mask] = im[mask]\n",
    "                \n",
    "                im_sharpness = cv2.Laplacian(im, cv2.CV_64F).var()\n",
    "                seg_sharpness = cv2.Laplacian(seg, cv2.CV_64F).var()\n",
    "                bg_sharpness = cv2.Laplacian(bg, cv2.CV_64F).var()\n",
    "                \n",
    "                X_im_sharpness.append(im_sharpness)\n",
    "                X_seg_sharpness.append(seg_sharpness)\n",
    "                X_bg_sharpness.append(bg_sharpness)\n",
    "                \n",
    "                y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "super-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51607,)\n",
      "(51607,)\n",
      "(51607,)\n",
      "(51607,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "X_im_sharpness = np.array(X_im_sharpness)\n",
    "X_bg_sharpness = np.array(X_bg_sharpness)\n",
    "X_seg_sharpness = np.array(X_seg_sharpness)\n",
    "\n",
    "print(y.shape)\n",
    "print(X_im_sharpness.shape)\n",
    "print(X_bg_sharpness.shape)\n",
    "print(X_seg_sharpness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "precise-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for X in [X_im_sharpness, X_bg_sharpness, X_seg_sharpness]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    clf.fit(X_train.reshape(-1,1), y_train)\n",
    "\n",
    "    acc_result = clf.score(X_test.reshape(-1,1), y_test)\n",
    "    results.append(acc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acting-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG+BG: 11.7\n",
      "BG: 10.8\n",
      "FG: 10.0\n"
     ]
    }
   ],
   "source": [
    "print('FG+BG:', np.round(results[0]*100, 1))\n",
    "print('BG:', np.round(results[1]*100, 1))\n",
    "print('FG:', np.round(results[2]*100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-choir",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
